{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvjeH9QI9wQm0gpGFvAqen",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/retroam/harmonizer/blob/develop/ocean_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade -q langchain deeplake openai tiktoken anthropic python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekrhrziyA7Q7",
        "outputId": "f5031587-4c36-48ec-8d75-69a74db2b3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/934.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.2/934.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m934.6/934.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m123.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for deeplake (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mdfe2_Lw8PYd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qk5ELqOUA7MM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fl = 'OpenClimate/harmonize/data/raw/BP_review/bp-stats-review-2022-all-data.xlsx'\n",
        "fl = os.path.abspath(fl)"
      ],
      "metadata": {
        "id": "h5NShbSp8jwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_wide_to_long(df=None,\n",
        "                    value_name=None,\n",
        "                    var_name=None):\n",
        "\n",
        "    # set default values (new column names)\n",
        "    # new column name with {value_vars}\n",
        "    var_name = \"year\" if var_name is None else var_name\n",
        "    # new column name with values\n",
        "    value_name = \"values\" if value_name is None else value_name\n",
        "\n",
        "    # ensure correct type\n",
        "    assert isinstance(df, pd.core.frame.DataFrame), f\"df must be a DataFrame\"\n",
        "    assert isinstance(var_name, str), f\"var_name must a be string\"\n",
        "    assert isinstance(value_name, str), f\"value_name must be a string\"\n",
        "\n",
        "    # ensure column names are strings\n",
        "    df.columns = df.columns.astype(str)\n",
        "\n",
        "    # columns to use as identifiers (columns that are not number)\n",
        "    id_vars = [val for val in list(df.columns) if not val.isdigit()]\n",
        "\n",
        "    # columns to unpivot (columns that are numbers)\n",
        "    value_vars = [val for val in list(df.columns) if val.isdigit()]\n",
        "\n",
        "    # Unpivot (melt) a DataFrame from wide to long format\n",
        "    df_long = df.melt(id_vars=id_vars,\n",
        "                      value_vars=value_vars,\n",
        "                      var_name=var_name,\n",
        "                      value_name=value_name)\n",
        "\n",
        "    # convert var_name column to int\n",
        "    df_long[var_name] = df_long[var_name].astype(int)\n",
        "\n",
        "    return df_long"
      ],
      "metadata": {
        "id": "d0PL7Y1q_V4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycountry\n",
        "from typing import List\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def country_lookup(name):\n",
        "    try:\n",
        "        return pycountry.countries.lookup(name).alpha_2\n",
        "    except LookupError:\n",
        "        return float('NaN')"
      ],
      "metadata": {
        "id": "Dpqag_UZA5AM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw = pd.read_excel(fl, sheet_name='CO2e Emissions', header=2)"
      ],
      "metadata": {
        "id": "M-f8_D61ttgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xl = pd.ExcelFile(fl)\n",
        "sheets = xl.sheet_names\n",
        "\n",
        "replace_dict = {\n",
        "    'Trinidad & Tobago': 'Trinidad and Tobago',\n",
        "    'China Hong Kong SAR': 'China',\n",
        "    'Iran': 'Iran, Islamic Republic of'\n",
        "}\n",
        "\n",
        "drop_columns = ['2021.1', '2011-21', '2021.2']\n",
        "rename_columns = {'Million tonnes of carbon dioxide equivalent': 'country'}\n",
        "country_groups = ['Central America', 'Eastern Africa', 'Middle Africa', 'Western Africa']\n",
        "not_countries = [\"Source:\", \"Notes:\", \"Growth\", \"Data \", \"European Union\", \"OECD\", \"0.05%\", \"Other \"]\n",
        "\n",
        "df = (\n",
        "    pd.read_excel(fl, sheet_name='CO2e Emissions', header=2)\n",
        "    .drop(columns = drop_columns)\n",
        "    .rename(columns = rename_columns)\n",
        "    .loc[lambda x: x['country'].notnull()]\n",
        "    .loc[lambda x: ~x['country'].str.contains('total', case=False)]\n",
        "    .loc[lambda x: ~x['country'].isin(country_groups)]\n",
        "    .loc[lambda x:  ~(x['country'].str.contains('|'.join(not_countries)))]\n",
        "    .assign(country = lambda x: x.country.replace(replace_dict))\n",
        ")\n",
        "\n",
        "# reshape dataframe\n",
        "df = df_wide_to_long(df, value_name='emissions', var_name='year')\n",
        "\n",
        "# convert from million metric tones to metric tonnes\n",
        "df['total_emissions'] = df['emissions'].apply(lambda x: x * 10**6)\n",
        "\n",
        "# get actor_id from country name\n",
        "df_iso = pd.DataFrame(\n",
        "    data=[(name, country_lookup(name)) for name in set(list(df.country))],\n",
        "    columns=['country', 'actor_id']\n",
        ")\n",
        "\n",
        "if not_found:=list(df_iso.loc[df_iso['actor_id'].isnull(), 'country']):\n",
        "    print(f\"Countries not found: {not_found}\")"
      ],
      "metadata": {
        "id": "Ht7oB4d__ihA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rWSpzSKh_uqE",
        "outputId": "cb758150-5f13-478e-ec2d-5d91f1136833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     country  year    emissions  total_emissions\n",
              "0     Canada  1990   480.394916     4.803949e+08\n",
              "1     Mexico  1990   315.852733     3.158527e+08\n",
              "2         US  1990  5275.397531     5.275398e+09\n",
              "3  Argentina  1990   123.904223     1.239042e+08\n",
              "4     Brazil  1990   217.067921     2.170679e+08"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4526b88e-8a30-4b5a-b3f5-be584b439a48\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>emissions</th>\n",
              "      <th>total_emissions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Canada</td>\n",
              "      <td>1990</td>\n",
              "      <td>480.394916</td>\n",
              "      <td>4.803949e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mexico</td>\n",
              "      <td>1990</td>\n",
              "      <td>315.852733</td>\n",
              "      <td>3.158527e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US</td>\n",
              "      <td>1990</td>\n",
              "      <td>5275.397531</td>\n",
              "      <td>5.275398e+09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Argentina</td>\n",
              "      <td>1990</td>\n",
              "      <td>123.904223</td>\n",
              "      <td>1.239042e+08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Brazil</td>\n",
              "      <td>1990</td>\n",
              "      <td>217.067921</td>\n",
              "      <td>2.170679e+08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4526b88e-8a30-4b5a-b3f5-be584b439a48')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4526b88e-8a30-4b5a-b3f5-be584b439a48 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4526b88e-8a30-4b5a-b3f5-be584b439a48');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw.head(2)"
      ],
      "metadata": {
        "id": "u8Dg9a-_BJGW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "118a3de4-7c81-4b12-85ab-c2575def0d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Million tonnes of carbon dioxide equivalent        1990        1991  \\\n",
              "0                                         NaN         NaN         NaN   \n",
              "1                                      Canada  480.394916  463.725716   \n",
              "\n",
              "         1992        1993        1994        1995        1996        1997  \\\n",
              "0         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "1  479.595415  477.188334  494.227769  515.442121  525.159938  539.822963   \n",
              "\n",
              "         1998  ...        2015        2016        2017        2018  \\\n",
              "0         NaN  ...         NaN         NaN         NaN         NaN   \n",
              "1  557.345635  ...  626.195347  609.108154  629.367081  642.112663   \n",
              "\n",
              "         2019        2020        2021    2021.1   2011-21    2021.2  \n",
              "0         NaN         NaN         NaN       NaN       NaN       NaN  \n",
              "1  639.321238  582.243625  595.422692  0.025437 -0.001249  0.015276  \n",
              "\n",
              "[2 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6487481-32e8-4337-803f-c8ad90551fec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Million tonnes of carbon dioxide equivalent</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>...</th>\n",
              "      <th>2015</th>\n",
              "      <th>2016</th>\n",
              "      <th>2017</th>\n",
              "      <th>2018</th>\n",
              "      <th>2019</th>\n",
              "      <th>2020</th>\n",
              "      <th>2021</th>\n",
              "      <th>2021.1</th>\n",
              "      <th>2011-21</th>\n",
              "      <th>2021.2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Canada</td>\n",
              "      <td>480.394916</td>\n",
              "      <td>463.725716</td>\n",
              "      <td>479.595415</td>\n",
              "      <td>477.188334</td>\n",
              "      <td>494.227769</td>\n",
              "      <td>515.442121</td>\n",
              "      <td>525.159938</td>\n",
              "      <td>539.822963</td>\n",
              "      <td>557.345635</td>\n",
              "      <td>...</td>\n",
              "      <td>626.195347</td>\n",
              "      <td>609.108154</td>\n",
              "      <td>629.367081</td>\n",
              "      <td>642.112663</td>\n",
              "      <td>639.321238</td>\n",
              "      <td>582.243625</td>\n",
              "      <td>595.422692</td>\n",
              "      <td>0.025437</td>\n",
              "      <td>-0.001249</td>\n",
              "      <td>0.015276</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6487481-32e8-4337-803f-c8ad90551fec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6487481-32e8-4337-803f-c8ad90551fec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6487481-32e8-4337-803f-c8ad90551fec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a bot that generates new parsing code from the current repository"
      ],
      "metadata": {
        "id": "BXkyVMN1u8_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqZtZMpDvBKs",
        "outputId": "1b9188cd-a52c-4430-afec-0cec416296df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "root_dir = '/content/OpenClimate/harmonize/scripts/'\n",
        "\n",
        "docs = []\n",
        "count = 0\n",
        "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
        "    for file in filenames:\n",
        "        if file.endswith('.py') and '/.venv/' not in dirpath:\n",
        "            try: \n",
        "                count += 1\n",
        "                loader = TextLoader(os.path.join(dirpath, file), encoding='utf-8')\n",
        "                docs.extend(loader.load_and_split())\n",
        "            except Exception as e: \n",
        "                pass\n",
        "print(f'{len(docs)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSYaIwGIv2Ud",
        "outputId": "eab3ca94-9570-4fa1-c9c5-3406f783bba6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1600, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(docs)\n",
        "print(f\"{len(texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHT1MiBJykkc",
        "outputId": "f4b648f1-99dc-4b90-b698-a35c6d48245e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi3GjThwy9TA",
        "outputId": "263d9b16-a682-4a96-ec73-0a0d3676bf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=None, openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEEPLAKE_ACCOUNT_NAME='katmphego'"
      ],
      "metadata": {
        "id": "-R3xo0NUzqjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import DeepLake\n",
        "\n",
        "db = DeepLake.from_documents(texts, embeddings, dataset_path=f\"hub://{DEEPLAKE_ACCOUNT_NAME}/ocean-code\")\n",
        "db"
      ],
      "metadata": {
        "id": "r8-s8LlfzHsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9c0e97-d3e0-447b-b47b-8b0ba397c57a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Deep Lake dataset has been successfully created!\n",
            "The dataset is private so make sure you are logged in!\n",
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/katmphego/ocean-code\n",
            "hub://katmphego/ocean-code loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 1/1 [00:15<00:00\n",
            "-"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://katmphego/ocean-code', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype      shape      dtype  compression\n",
            "  -------   -------    -------    -------  ------- \n",
            " embedding  generic  (467, 1536)  float32   None   \n",
            "    ids      text     (467, 1)      str     None   \n",
            " metadata    json     (467, 1)      str     None   \n",
            "   text      text     (467, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.vectorstores.deeplake.DeepLake at 0x7fb63ccd33d0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()\n",
        "retriever.search_kwargs['distance_metric'] = 'cos'\n",
        "retriever.search_kwargs['fetch_k'] = 20\n",
        "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
        "retriever.search_kwargs['k'] = 20"
      ],
      "metadata": {
        "id": "Y-vJsWPrzuON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "\n",
        "model = ChatOpenAI(model_name='gpt-4') # 'ada' 'gpt-3.5-turbo' 'gpt-4',\n",
        "qa = ConversationalRetrievalChain.from_llm(model,retriever=retriever)"
      ],
      "metadata": {
        "id": "cHd5Byrr0Pet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_ex = raw.head(2).to_markdown()\n",
        "clean_ex = df.head(2).to_markdown()"
      ],
      "metadata": {
        "id": "6cXMJMol3U7F"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (f\"\"\"\n",
        "I have two datasets that have different data schemas and I want to harmonize \n",
        "them so that they use the same one. Can you provide python code that \n",
        "would turn Data Schema B into the same structure as Data Schema A. Use prior code\n",
        "as a starting point\n",
        "    \n",
        "    Data A examples is:\n",
        "\n",
        "    {clean_ex}\n",
        "    \n",
        "    Data  B example is:\n",
        "\n",
        "    {raw_ex}\n",
        "    \n",
        "    Provide the python code explaining what each part does in its transformation? Be concise\n",
        "    \n",
        "    Thank you\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "V4ZYlRpC2A1y"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "\"\"\"\n",
        "what does the codebase do\n",
        "\"\"\",\n",
        "\"can you write a single code file that replaces all the code?\",\n",
        "prompt\n",
        "] \n",
        "chat_history = []\n",
        "\n",
        "for question in questions:  \n",
        "    result = qa({\"question\": question, \"chat_history\": chat_history})\n",
        "    chat_history.append((question, result['answer']))\n",
        "    print(f\"-> **Question**: {question} \\n\")\n",
        "    print(f\"**Answer**: {result['answer']} \\n\")"
      ],
      "metadata": {
        "id": "dZ5MXtv-0YGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e33bd143-d200-44e9-b2dd-f556018625aa"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-> **Question**: \n",
            "what does the codebase do\n",
            " \n",
            "\n",
            "**Answer**: The codebase provided consists of multiple scripts that primarily perform the following tasks:\n",
            "\n",
            "1. Process and harmonize various climate-related datasets, such as emissions data, climate targets, and other related information from different sources, like CDP (Carbon Disclosure Project), World Bank, UNFCCC (United Nations Framework Convention on Climate Change), Climate Mayors, and others.\n",
            "\n",
            "2. Extract relevant data, such as country codes, actor names, territories, and other information from these datasets.\n",
            "\n",
            "3. Create output directories, process data, and store the results in CSV files.\n",
            "\n",
            "4. Generate tables for publishers, datasources, and other metadata associated with the datasets.\n",
            "\n",
            "The codebase makes use of Python libraries like pandas, numpy, and others to manipulate and process the data effectively. \n",
            "\n",
            "-> **Question**: can you write a single code file that replaces all the code? \n",
            "\n",
            "**Answer**: It's not possible to create a single code file that replaces the entire existing codebase, as the provided codebase is quite extensive and consists of multiple files with different functionalities. Moreover, combining all the code into a single file would make it harder to maintain, understand, and debug.\n",
            "\n",
            "Instead, it's recommended to organize the codebase into separate modules and files based on their specific functionalities. This modular approach improves readability, maintainability, and collaboration among developers. \n",
            "\n",
            "-> **Question**: \n",
            "I have two datasets that have different data schemas and I want to harmonize \n",
            "them so that they use the same one. Can you provide python code that \n",
            "would turn Data Schema B into the same structure as Data Schema A. Use prior code\n",
            "as a starting point\n",
            "    \n",
            "    Data A examples is:\n",
            "\n",
            "    |    | country   |   year |   emissions |   total_emissions |\n",
            "|---:|:----------|-------:|------------:|------------------:|\n",
            "|  0 | Canada    |   1990 |     480.395 |       4.80395e+08 |\n",
            "|  1 | Mexico    |   1990 |     315.853 |       3.15853e+08 |\n",
            "    \n",
            "    Data  B example is:\n",
            "\n",
            "    |    | Million tonnes of carbon dioxide equivalent   |    1990 |    1991 |    1992 |    1993 |    1994 |    1995 |   1996 |    1997 |    1998 |    1999 |    2000 |    2001 |    2002 |    2003 |    2004 |    2005 |    2006 |    2007 |    2008 |    2009 |    2010 |   2011 |    2012 |    2013 |    2014 |    2015 |    2016 |    2017 |    2018 |    2019 |    2020 |    2021 |      2021.1 |      2011-21 |      2021.2 |\n",
            "|---:|:----------------------------------------------|--------:|--------:|--------:|--------:|--------:|--------:|-------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|-------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|------------:|-------------:|------------:|\n",
            "|  0 | nan                                           | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan         | nan          | nan         |\n",
            "|  1 | Canada                                        | 480.395 | 463.726 | 479.595 | 477.188 | 494.228 | 515.442 | 525.16 | 539.823 | 557.346 | 561.178 | 582.357 | 584.936 | 598.555 | 608.419 | 606.658 | 606.717 | 602.173 | 629.267 | 611.532 | 580.034 | 596.705 | 602.91 | 600.543 | 616.126 | 625.744 | 626.195 | 609.108 | 629.367 | 642.113 | 639.321 | 582.244 | 595.423 |   0.0254367 |  -0.00124894 |   0.0152764 |\n",
            "    \n",
            "    Provide the python code explaining what each part does in its transformation? Be concise\n",
            "    \n",
            "    Thank you\n",
            " \n",
            "\n",
            "**Answer**: Certainly! Based on the information provided, Dataset A has a long format, while Dataset B has a wide format. We will first transform Dataset B into the long format and then rename the columns to match the structure of Dataset A. Here's the Python code for this transformation:\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "\n",
            "# Assuming Dataset B is loaded as a DataFrame named df_b\n",
            "# Columns: ['country', '1990', '1991', '1992', ...]\n",
            "\n",
            "# Melt the wide format DataFrame (Dataset B) into a long format\n",
            "df_b_long = pd.melt(df_b, id_vars=['country'], var_name='year', value_name='emissions')\n",
            "\n",
            "# Calculate the total_emissions column based on the 'emissions' column\n",
            "# (Modify this calculation if necessary, as it's not clear how it's derived in Dataset A)\n",
            "df_b_long['total_emissions'] = df_b_long['emissions']\n",
            "\n",
            "# Rename the columns to match Dataset A\n",
            "df_b_long = df_b_long.rename(columns={'country': 'Country', 'year': 'Year', 'emissions': 'Emissions', 'total_emissions': 'Total_Emissions'})\n",
            "\n",
            "# Now, df_b_long has the same structure as Dataset A\n",
            "```\n",
            "\n",
            "Here's a breakdown of the transformation code:\n",
            "\n",
            "1. Import the pandas library: This allows us to work with DataFrames, which are used to manipulate and analyze datasets.\n",
            "\n",
            "```python\n",
            "import pandas as pd\n",
            "```\n",
            "\n",
            "2. Melt the wide format DataFrame (Dataset B) into a long format: The `pd.melt()` function is used to convert a wide format DataFrame into a long format by moving the year columns (e.g., '1990', '1991', etc.) into a single 'year' column and their corresponding values into an 'emissions' column.\n",
            "\n",
            "```python\n",
            "df_b_long = pd.melt(df_b, id_vars=['country'], var_name='year', value_name='emissions')\n",
            "```\n",
            "\n",
            "3. Calculate the total_emissions column based on the 'emissions' column: Since it's not clear how 'total_emissions' is derived in Dataset A, we assume it's the same as the 'emissions' column. Modify this calculation if necessary.\n",
            "\n",
            "```python\n",
            "df_b_long['total_emissions'] = df_b_long['emissions']\n",
            "```\n",
            "\n",
            "4. Rename the columns to match Dataset A: To ensure the column names in Dataset B match Dataset A, we use the `rename()` function.\n",
            "\n",
            "```python\n",
            "df_b_long = df_b_long.rename(columns={'country': 'Country', 'year': 'Year', 'emissions': 'Emissions', 'total_emissions': 'Total_Emissions'})\n",
            "```\n",
            "\n",
            "Now, `df_b_long` has the same structure as Dataset A, with columns 'Country', 'Year', 'Emissions', and 'Total_Emissions'. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uqbxrF-e1eSi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}